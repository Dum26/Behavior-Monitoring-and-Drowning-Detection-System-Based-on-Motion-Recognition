import os
import cv2
import numpy as np
from ultralytics import YOLO
from tqdm import tqdm # Cáº§n cÃ i Ä‘áº·t: pip install tqdm

# --- Cáº¤U HÃŒNH ---
# ÄÆ°á»ng dáº«n Ä‘áº¿n thÆ° má»¥c train chá»©a 2 folder con lÃ  'images' vÃ  'labels'
DATASET_ROOT = r"D:\thi_nghiem_AI\dataset\train" 
IMAGES_DIR = os.path.join(DATASET_ROOT, "images")
LABELS_DIR = os.path.join(DATASET_ROOT, "labels")

# Chuá»—i giáº£ láº­p (NhÃ¢n báº£n 1 áº£nh thÃ nh 30 frames)
SEQ_LENGTH = 30  

print("â³ Äang táº£i mÃ´ hÃ¬nh YOLOv8-Pose...")
model = YOLO('yolov8n-pose.pt')

def get_feature_vector(image_path):
    """TrÃ­ch xuáº¥t 17 khá»›p xÆ°Æ¡ng vÃ  lÃ m pháº³ng thÃ nh vector 51 chiá»u"""
    try:
        img = cv2.imread(image_path)
        if img is None: return None
        
        # Cháº¡y YOLO Pose
        results = model(img, verbose=False)
        
        for result in results:
            if result.keypoints is None: continue
            
            # Kiá»ƒm tra náº¿u khÃ´ng tÃ¬m tháº¥y ngÆ°á»i nÃ o
            if result.keypoints.xyn.shape[0] == 0:
                continue
                
            # Láº¥y ngÆ°á»i Ä‘áº§u tiÃªn tÃ¬m tháº¥y
            keypoints_xyn = result.keypoints.xyn.cpu().numpy()[0]  # (17, 2)
            keypoints_conf = result.keypoints.conf.cpu().numpy()[0] # (17,)
            
            # GhÃ©p láº¡i: [x, y, conf] -> Shape (17, 3)
            keypoints_combined = np.column_stack((keypoints_xyn, keypoints_conf))
            
            return keypoints_combined.flatten() # 51 chiá»u
    except Exception as e:
        pass
    return None

def create_dataset():
    X_data = []
    y_data = []
    
    if not os.path.exists(IMAGES_DIR) or not os.path.exists(LABELS_DIR):
        print(f"âŒ Lá»–I: KhÃ´ng tÃ¬m tháº¥y thÆ° má»¥c 'images' hoáº·c 'labels' táº¡i {DATASET_ROOT}")
        return

    print(f" Báº¯t Ä‘áº§u quÃ©t dá»¯ liá»‡u...")
    image_files = [f for f in os.listdir(IMAGES_DIR) if f.lower().endswith(('.jpg', '.png'))]
    
    count_success = 0
    count_skipped = 0

    for img_file in tqdm(image_files, desc="Äang xá»­ lÃ½"):
        label_file = os.path.splitext(img_file)[0] + ".txt"
        label_path = os.path.join(LABELS_DIR, label_file)
        img_path = os.path.join(IMAGES_DIR, img_file)

        if not os.path.exists(label_path): continue
            
        try:
            with open(label_path, 'r') as f:
                lines = f.readlines()
                if not lines: continue
                
                # Láº¥y Class ID tá»« dÃ²ng Ä‘áº§u tiÃªn
                first_line = lines[0].strip().split()
                class_id = int(first_line[0]) 
                
                # TrÃ­ch xuáº¥t Ä‘áº·c trÆ°ng
                vector_51 = get_feature_vector(img_path)
                
                if vector_51 is not None:
                    # NhÃ¢n báº£n thÃ nh chuá»—i 30 frames
                    sequence = np.tile(vector_51, (SEQ_LENGTH, 1))
                    X_data.append(sequence)
                    y_data.append(class_id)
                    count_success += 1
                else:
                    count_skipped += 1
        except:
            continue

    X = np.array(X_data)
    y = np.array(y_data)

    print(f"\nâœ… HoÃ n táº¥t! Sá»‘ lÆ°á»£ng máº«u: {count_success}")
    if len(X) > 0:
        np.save('X_train_data.npy', X)
        np.save('y_train_data.npy', y)
        print("ğŸ’¾ ÄÃ£ lÆ°u file .npy thÃ nh cÃ´ng.")

if __name__ == "__main__":
    create_dataset()