import numpy as np
import os
import sys

# Kiá»ƒm tra xem thÆ° viá»‡n TensorFlow Ä‘Ã£ Ä‘Æ°á»£c cÃ i Ä‘áº·t chÆ°a
try:
    import tensorflow as tf
    from tensorflow.keras.models import Sequential
    from tensorflow.keras.layers import LSTM, Dense, Dropout
    from tensorflow.keras.utils import to_categorical
    from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
    from sklearn.model_selection import train_test_split
    print(f"âœ… ÄÃ£ tÃ¬m tháº¥y TensorFlow phiÃªn báº£n: {tf.__version__}")
except ImportError:
    print("âŒ Lá»–I: ChÆ°a cÃ i Ä‘áº·t TensorFlow.")
    print("ğŸ‘‰ HÃ£y cháº¡y lá»‡nh: pip install tensorflow")
    sys.exit(1)

# --- 1. Cáº¤U HÃŒNH THAM Sá» ---
# CÃ¡c thÃ´ng sá»‘ nÃ y PHáº¢I khá»›p vá»›i file make_data_yolo.py
SEQUENCE_LENGTH = 30    # Äá»™ dÃ i chuá»—i (sá»‘ frames)
FEATURE_VECTOR_SIZE = 51 # KÃ­ch thÆ°á»›c vector Ä‘áº·c trÆ°ng (17 khá»›p * 3 thÃ´ng sá»‘)

# TÃªn file model sáº½ lÆ°u
MODEL_SAVE_PATH = 'action_classifier_lstm.h5'
BEST_MODEL_SAVE_PATH = 'best_action_classifier.h5'

def build_lstm_model(input_shape, num_classes):
    """
    XÃ¢y dá»±ng kiáº¿n trÃºc mÃ´ hÃ¬nh LSTM.
    Kiáº¿n trÃºc nÃ y Ä‘Æ°á»£c tinh chá»‰nh Ä‘á»ƒ hoáº¡t Ä‘á»™ng tá»‘t vá»›i dá»¯ liá»‡u xÆ°Æ¡ng khá»›p (skeleton).
    """
    model = Sequential()

    # Layer LSTM 1: Tráº£ vá» chuá»—i (return_sequences=True) Ä‘á»ƒ lá»›p sau tiáº¿p tá»¥c xá»­ lÃ½
    # Input shape: (30, 51)
    model.add(LSTM(units=64, return_sequences=True, input_shape=input_shape))
    model.add(Dropout(0.2)) # Dropout giÃºp chá»‘ng há»c váº¹t (Overfitting)

    # Layer LSTM 2: Tráº£ vá» káº¿t quáº£ tÃ³m táº¯t cuá»‘i cÃ¹ng (return_sequences=False)
    model.add(LSTM(units=32, return_sequences=False))
    model.add(Dropout(0.2))

    # Layer Dense: Lá»›p nÆ¡-ron káº¿t ná»‘i Ä‘áº§y Ä‘á»§ Ä‘á»ƒ há»c cÃ¡c Ä‘áº·c trÆ°ng phi tuyáº¿n tÃ­nh
    model.add(Dense(units=32, activation='relu'))

    # Output Layer: Tráº£ vá» xÃ¡c suáº¥t cho tá»«ng lá»›p (dÃ¹ng Softmax cho phÃ¢n loáº¡i Ä‘a lá»›p)
    model.add(Dense(units=num_classes, activation='softmax'))

    # BiÃªn dá»‹ch mÃ´ hÃ¬nh
    model.compile(optimizer='adam', 
                  loss='categorical_crossentropy', 
                  metrics=['accuracy'])
    return model

def train_model():
    print("\n--- BÆ¯á»šC 1: Táº¢I Dá»® LIá»†U ---")
    
    # Kiá»ƒm tra file dá»¯ liá»‡u cÃ³ tá»“n táº¡i khÃ´ng
    if not os.path.exists('X_train_data.npy') or not os.path.exists('y_train_data.npy'):
        print("âŒ Lá»–I: KhÃ´ng tÃ¬m tháº¥y file dá»¯ liá»‡u .npy!")
        print("ğŸ‘‰ Báº¡n Cáº¦N cháº¡y file 'make_data_yolo.py' trÆ°á»›c Ä‘á»ƒ táº¡o dá»¯ liá»‡u tá»« áº£nh.")
        return

    # Táº£i dá»¯ liá»‡u tá»« file .npy
    print("â³ Äang Ä‘á»c file X_train_data.npy vÃ  y_train_data.npy...")
    X = np.load('X_train_data.npy')
    y = np.load('y_train_data.npy')

    # In thÃ´ng tin dá»¯ liá»‡u Ä‘á»ƒ kiá»ƒm tra
    print(f"   - Tá»•ng sá»‘ máº«u dá»¯ liá»‡u: {X.shape[0]}")
    print(f"   - KÃ­ch thÆ°á»›c chuá»—i (Frames): {X.shape[1]}")
    print(f"   - Äáº·c trÆ°ng má»—i frame: {X.shape[2]}")

    # Tá»± Ä‘á»™ng xÃ¡c Ä‘á»‹nh sá»‘ lÆ°á»£ng lá»›p (Classes) tá»« dá»¯ liá»‡u
    unique_classes = np.unique(y)
    num_classes = len(unique_classes)
    print(f"   - Sá»‘ lÆ°á»£ng lá»›p tÃ¬m tháº¥y: {num_classes}")
    print(f"   - CÃ¡c nhÃ£n ID: {unique_classes}")

    print("\n--- BÆ¯á»šC 2: CHUáº¨N Bá»Š TRAINING ---")
    
    # Chuyá»ƒn Ä‘á»•i nhÃ£n sang dáº¡ng One-hot vector 
    # VÃ­ dá»¥: náº¿u cÃ³ 3 lá»›p, nhÃ£n 1 sáº½ thÃ nh [0, 1, 0]
    y_one_hot = to_categorical(y, num_classes=num_classes)

    # Chia dá»¯ liá»‡u: 80% Ä‘á»ƒ há»c (Train), 20% Ä‘á»ƒ kiá»ƒm tra (Test)
    X_train, X_test, y_train, y_test = train_test_split(X, y_one_hot, test_size=0.2, random_state=42)
    print(f"   - Dá»¯ liá»‡u dÃ¹ng Ä‘á»ƒ Train: {X_train.shape[0]} máº«u")
    print(f"   - Dá»¯ liá»‡u dÃ¹ng Ä‘á»ƒ Test: {X_test.shape[0]} máº«u")

    # XÃ¢y dá»±ng mÃ´ hÃ¬nh
    model = build_lstm_model((SEQUENCE_LENGTH, FEATURE_VECTOR_SIZE), num_classes)
    model.summary() # In cáº¥u trÃºc mÃ´ hÃ¬nh ra mÃ n hÃ¬nh

    # Thiáº¿t láº­p cÃ¡c chiáº¿n lÆ°á»£c Training (Callbacks)
    callbacks = [
        # Dá»«ng sá»›m náº¿u sau 15 vÃ²ng (patience) mÃ  Ä‘á»™ lá»—i khÃ´ng giáº£m thÃªm -> Tiáº¿t kiá»‡m thá»i gian
        EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True, verbose=1),
        
        # LuÃ´n lÆ°u láº¡i phiÃªn báº£n mÃ´ hÃ¬nh tá»‘t nháº¥t (cÃ³ val_loss tháº¥p nháº¥t) trong quÃ¡ trÃ¬nh cháº¡y
        ModelCheckpoint(BEST_MODEL_SAVE_PATH, monitor='val_loss', save_best_only=True, verbose=1)
    ]

    print("\n--- BÆ¯á»šC 3: Báº®T Äáº¦U HUáº¤N LUYá»†N (TRAINING) ---")
    print("ğŸš€ QuÃ¡ trÃ¬nh nÃ y cÃ³ thá»ƒ máº¥t vÃ i phÃºt tÃ¹y vÃ o lÆ°á»£ng dá»¯ liá»‡u...")
    
    # Báº¯t Ä‘áº§u training
    history = model.fit(
        X_train, y_train,
        epochs=100,         # Sá»‘ vÃ²ng láº·p tá»‘i Ä‘a (náº¿u khÃ´ng bá»‹ dá»«ng sá»›m)
        batch_size=32,      # Sá»‘ lÆ°á»£ng máº«u há»c má»—i láº§n cáº­p nháº­t trá»ng sá»‘
        validation_data=(X_test, y_test), # Dá»¯ liá»‡u Ä‘á»ƒ kiá»ƒm tra chÃ©o
        callbacks=callbacks
    )

    print("\n--- BÆ¯á»šC 4: ÄÃNH GIÃ Káº¾T QUáº¢ ---")
    # ÄÃ¡nh giÃ¡ Ä‘á»™ chÃ­nh xÃ¡c cuá»‘i cÃ¹ng trÃªn táº­p Test
    loss, accuracy = model.evaluate(X_test, y_test)
    print(f"ğŸ“Š Káº¿t quáº£ trÃªn táº­p Test:")
    print(f"   - Loss: {loss:.4f}")
    print(f"   - Accuracy (Äá»™ chÃ­nh xÃ¡c): {accuracy*100:.2f}%")

    # LÆ°u mÃ´ hÃ¬nh cuá»‘i cÃ¹ng vÃ o file .h5
    model.save(MODEL_SAVE_PATH)
    print(f"\nâœ… ÄÃ£ lÆ°u mÃ´ hÃ¬nh thÃ nh cÃ´ng táº¡i: {MODEL_SAVE_PATH}")
    print(f"ğŸ‘‰ BÃ¢y giá» báº¡n cÃ³ thá»ƒ cháº¡y file 'detect_people.py' hoáº·c 'run_demo.py' Ä‘á»ƒ kiá»ƒm tra káº¿t quáº£!")

if __name__ == '__main__':
    train_model()