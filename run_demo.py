import cv2
import numpy as np
import argparse
import time
from collections import deque, Counter
from ultralytics import YOLO
import sys
import os

# Cá»‘ gáº¯ng import TensorFlow Ä‘á»ƒ load model LSTM
try:
    from tensorflow.keras.models import load_model
    TENSORFLOW_AVAILABLE = True
except ImportError:
    print("âŒ Lá»–I: ChÆ°a cÃ i TensorFlow. Cháº¡y: pip install tensorflow")
    TENSORFLOW_AVAILABLE = False

# --- Cáº¤U HÃŒNH Há»† THá»NG ---
POSE_MODEL_PATH = 'yolov8n-pose.pt' 
LSTM_MODEL_PATH = 'action_classifier_lstm.h5' 

# âš ï¸ QUAN TRá»ŒNG: Náº¿u nháº­n diá»‡n bá»‹ NGÆ¯á»¢C (BÆ¡i thÃ nh Äuá»‘i), hÃ£y thá»­ Ä‘á»•i chá»— tÃªn trong danh sÃ¡ch nÃ y
LABELS = {
    0: 'DROWNING', 
    1: 'SWIMMING', 
    2: 'OUT_OF_WATER'
}

# Cáº¥u hÃ¬nh mÃ u sáº¯c (BGR)
COLORS = {
    'DROWNING': (0, 0, 255),      # Äá»Ž
    'SWIMMING': (0, 255, 0),      # XANH LÃ
    'OUT_OF_WATER': (0, 255, 255),# VÃ€NG
    'Unknown': (128, 128, 128)    # XÃM
}

# Cáº¥u hÃ¬nh Voting
HISTORY_LENGTH = 15
LSTM_CONFIDENCE_THRESHOLD = 0.6 # Chá»‰ tin náº¿u xÃ¡c suáº¥t > 60%
voting_buffer = {} 

def run_system(source):
    print("â³ Äang táº£i YOLOv8-Pose...")
    try:
        pose_model = YOLO(POSE_MODEL_PATH)
    except Exception as e:
        print(f"âŒ Lá»—i táº£i YOLO: {e}")
        return
    
    action_model = None
    if TENSORFLOW_AVAILABLE:
        print(f"â³ Äang táº£i LSTM Model: {LSTM_MODEL_PATH}...")
        if os.path.exists(LSTM_MODEL_PATH):
            try:
                action_model = load_model(LSTM_MODEL_PATH)
                print("âœ… ÄÃ£ táº£i xong LSTM!")
            except Exception as e:
                 print(f"âŒ Lá»—i khi load file h5: {e}")
                 return
        else:
            print("âŒ KhÃ´ng tÃ¬m tháº¥y file model. HÃ£y cháº¡y train_lstm.py trÆ°á»›c!")
            return

    cap = cv2.VideoCapture(source)
    if not cap.isOpened():
        print(f"âŒ KhÃ´ng má»Ÿ Ä‘Æ°á»£c nguá»“n: {source}")
        return

    print("ðŸš€ Há»† THá»NG Báº®T Äáº¦U! Nháº¥n 'q' Ä‘á»ƒ thoÃ¡t.")

    while True:
        ret, frame = cap.read()
        if not ret: break

        # Tracking vá»›i YOLO
        results = pose_model.track(frame, persist=True, verbose=False, conf=0.5)
        
        if results[0].boxes.id is not None:
            track_ids = results[0].boxes.id.int().cpu().tolist()
            
            for i, track_id in enumerate(track_ids):
                # --- A. TRÃCH XUáº¤T ---
                kpts_xyn = results[0].keypoints.xyn.cpu().numpy()[i]
                kpts_conf = results[0].keypoints.conf.cpu().numpy()[i]
                vector_51 = np.column_stack((kpts_xyn, kpts_conf)).flatten()
                input_sequence = np.tile(vector_51, (30, 1)).reshape(1, 30, 51)
                
                final_label = "Scanning..."
                confidence = 0.0
                probs = [] # Äá»ƒ hiá»ƒn thá»‹ debug
                
                # --- B. LSTM Dá»° ÄOÃN ---
                if action_model:
                    pred = action_model.predict(input_sequence, verbose=0)[0]
                    current_label_idx = np.argmax(pred)
                    current_conf = pred[current_label_idx]
                    probs = pred # LÆ°u láº¡i Ä‘á»ƒ váº½
                    
                    # Chá»‰ thÃªm vÃ o bá»™ nhá»› náº¿u Ä‘á»™ tin cáº­y Ä‘á»§ cao
                    if current_conf > LSTM_CONFIDENCE_THRESHOLD:
                        if track_id not in voting_buffer:
                            voting_buffer[track_id] = deque(maxlen=HISTORY_LENGTH)
                        voting_buffer[track_id].append(current_label_idx)
                    
                    # Voting
                    if track_id in voting_buffer and len(voting_buffer[track_id]) > 0:
                        votes = Counter(voting_buffer[track_id])
                        winner_idx, count = votes.most_common(1)[0]
                        # Náº¿u nhÃ£n tháº¯ng cuá»™c chiáº¿m Æ°u tháº¿
                        if count >= 1: # Láº¥y káº¿t quáº£ phá»• biáº¿n nháº¥t
                            final_label = LABELS.get(winner_idx, "Unknown")
                            confidence = pred[winner_idx] # Láº¥y conf cá»§a frame hiá»‡n táº¡i cho nhÃ£n Ä‘Ã³

                # --- C. Váº¼ Káº¾T QUáº¢ ---
                box = results[0].boxes.xyxy.cpu().numpy()[i].astype(int)
                color = COLORS.get(final_label, (255, 255, 255))
                
                # Khung ngÆ°á»i
                cv2.rectangle(frame, (box[0], box[1]), (box[2], box[3]), color, 2)
                
                # NhÃ£n chÃ­nh
                text = f"ID:{track_id} {final_label}"
                if action_model and final_label != "Scanning...":
                     text += f" ({confidence:.2f})"
                
                # Vá»‹ trÃ­ váº½ chá»¯
                text_y = box[1] - 10 if box[1] - 10 > 20 else box[1] + 20
                cv2.putText(frame, text, (box[0], text_y), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)

                # --- D. Váº¼ DEBUG (XÃC SUáº¤T CHI TIáº¾T) ---
                # GiÃºp báº¡n biáº¿t táº¡i sao nÃ³ nháº­n sai
                if len(probs) > 0:
                    dy = 25
                    for idx, prob in enumerate(probs):
                        label_name = LABELS.get(idx, str(idx))
                        debug_text = f"{label_name}: {prob:.2f}"
                        # Váº½ chá»¯ nhá» bÃªn cáº¡nh há»™p
                        cv2.putText(frame, debug_text, (box[2] + 5, box[1] + dy * (idx + 1)), 
                                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)

                # Váº½ xÆ°Æ¡ng khá»›p
                kpts_pixel = results[0].keypoints.xy.cpu().numpy()[i]
                for kp in kpts_pixel:
                    x, y = int(kp[0]), int(kp[1])
                    if x > 0 and y > 0:
                        cv2.circle(frame, (x, y), 3, (0, 255, 255), -1)

        cv2.imshow('Drowning Detection (Debug Mode)', frame)
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    cap.release()
    cv2.destroyAllWindows()

if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--source', type=str, default='0', help='Path to video file or 0 for Webcam')
    args = parser.parse_args()
    try:
        src = int(args.source)
    except ValueError:
        src = args.source
    run_system(src)