import cv2
from ultralytics import YOLO
import argparse
import sys
import os # Import os ƒë·ªÉ ki·ªÉm tra ƒë∆∞·ªùng d·∫´n file

# --- C·∫•u h√¨nh M√¥ h√¨nh v√† Nh·∫≠n d·∫°ng ---
# ƒê·∫£m b·∫£o ƒë∆∞·ªùng d·∫´n n√†y ƒë√∫ng v·ªõi v·ªã tr√≠ file yolov8n.pt c·ªßa b·∫°n
MODEL_PATH = 'models/yolov8n.pt' 

# L·ªõp 'person' trong b·ªô d·ªØ li·ªáu COCO l√† class ID 0
TARGET_CLASS_ID = 0 
CLASS_NAME = 'person'
CONFIDENCE_THRESHOLD = 0.5 

# T·∫£i m√¥ h√¨nh YOLOv8
try:
    model = YOLO(MODEL_PATH) 
except Exception as e:
    print("----------------------------------------------------------------")
    print(f"L·ªñI T·∫¢I M√î H√åNH: Kh√¥ng t√¨m th·∫•y {MODEL_PATH}")
    print("Vui l√≤ng ƒë·∫£m b·∫£o file 'yolov8n.pt' n·∫±m trong th∆∞ m·ª•c 'models'.")
    print(f"Chi ti·∫øt l·ªói: {e}")
    print("----------------------------------------------------------------")
    sys.exit(1) # Tho√°t ch∆∞∆°ng tr√¨nh n·∫øu kh√¥ng t·∫£i ƒë∆∞·ª£c m√¥ h√¨nh

def detect_people_and_draw_bbox(frame):
    """
    Th·ª±c hi·ªán ph√°t hi·ªán ƒë·ªëi t∆∞·ª£ng ng∆∞·ªùi tr√™n m·ªôt khung h√¨nh v√† v·∫Ω bounding box.
    """
    # 1. Ch·∫°y m√¥ h√¨nh d·ª± ƒëo√°n
    # S·ª≠ d·ª•ng 'classes=0' v√† 'conf' tr·ª±c ti·∫øp trong h√†m model()
    results = model(frame, classes=[TARGET_CLASS_ID], conf=CONFIDENCE_THRESHOLD, verbose=False)
    
    # Duy·ªát qua c√°c k·∫øt qu·∫£ d·ª± ƒëo√°n
    for result in results:
        # L·∫•y th√¥ng tin bounding box v√† ƒë·ªô tin c·∫≠y
        boxes = result.boxes.xyxy.cpu().numpy().astype(int) 
        confidences = result.boxes.conf.cpu().numpy()
        
        for box, conf in zip(boxes, confidences):
            x1, y1, x2, y2 = box
            
            # V·∫Ω bounding box (m√†u xanh l√° c√¢y)
            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
            
            # Ghi nh√£n l√™n h·ªôp (t√™n l·ªõp v√† ƒë·ªô tin c·∫≠y)
            label = f"{CLASS_NAME}: {conf:.2f}"
            cv2.putText(frame, label, (x1, y1 - 10), 
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
                
    return frame

## üé• H√†m Ch√≠nh ƒë·ªÉ X·ª≠ l√Ω Lu·ªìng Camera/Video

def process_video_stream(source):
    """
    Kh·ªüi ƒë·ªông lu·ªìng camera ho·∫∑c ƒë·ªçc t·ª´ file video.
    :param source: 0 (ho·∫∑c s·ªë kh√°c) cho camera, ho·∫∑c ƒë∆∞·ªùng d·∫´n file video.
    """
    # Kh·ªüi t·∫°o VideoCapture
    cap = cv2.VideoCapture(source)
    if not cap.isOpened():
        print(f"L·ªñI: Kh√¥ng th·ªÉ m·ªü ngu·ªìn video/camera: {source}.")
        
        # N·∫øu source l√† file, ki·ªÉm tra xem file c√≥ t·ªìn t·∫°i kh√¥ng
        if isinstance(source, str) and not os.path.exists(source):
            print(f"L·ªñI: ƒê∆∞·ªùng d·∫´n file '{source}' kh√¥ng t·ªìn t·∫°i.")
        return

    print(f"B·∫Øt ƒë·∫ßu ph√°t hi·ªán ng∆∞·ªùi t·ª´ ngu·ªìn: {source}. Nh·∫•n 'q' ƒë·ªÉ tho√°t.")
    
    while True:
        ret, frame = cap.read()
        if not ret:
            print("ƒê√£ k·∫øt th√∫c video ho·∫∑c l·ªói ƒë·ªçc frame.")
            break

        # Th·ª±c hi·ªán ph√°t hi·ªán v√† v·∫Ω bounding box
        processed_frame = detect_people_and_draw_bbox(frame)

        # Hi·ªÉn th·ªã k·∫øt qu·∫£
        cv2.imshow('YOLOv8 People Detection', processed_frame)

        # Tho√°t khi nh·∫•n 'q'
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    cap.release()
    cv2.destroyAllWindows()

# --- CH·∫†Y CH∆Ø∆†NG TR√åNH V·ªöI ARGPARSE ---
if __name__ == '__main__':
    parser = argparse.ArgumentParser(description="YOLOv8 People Detector")
    
    parser.add_argument('--source', type=str, default='0', 
                        help='Input source: 0 for default camera, or path to a video file.')
    
    args = parser.parse_args()

    # X·ª≠ l√Ω input: s·ªë (camera ID) hay chu·ªói (ƒë∆∞·ªùng d·∫´n file)
    try:
        source_id = int(args.source)
        process_video_stream(source_id)
    except ValueError:
        process_video_stream(args.source)
# python object_people.py
# python object_people.py --source "D:\thi_nghiem_AI\dataset\video\drowning_1.mp4"